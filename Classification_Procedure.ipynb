{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from scipy import stats\n",
    "import pyts\n",
    "import sklearn\n",
    "from pyts.classification import KNeighborsClassifier\n",
    "from pyts.datasets import load_gunpoint\n",
    "from sktime.distances import distance\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from pyts.classification import TimeSeriesForest\n",
    "from pyts.classification import BOSSVS\n",
    "from pyts.classification import SAXVSM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from tslearn.svm import TimeSeriesSVC\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import rpy2.robjects.packages as rpackages\n",
    "import rpy2.robjects as robjects\n",
    "from pyts import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29665d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas2ri.activate()\n",
    "utils = rpackages.importr('utils')s\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "Tdist = importr('TSdist')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_Procedure():\n",
    "\n",
    "    def __init__(self,path, X_train, X_test, y_train, y_test,splits_number=0):\n",
    "        \n",
    "        self.path=path\n",
    "        \n",
    "        self.splits_number=splits_number\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        self.X= np.concatenate((X_train, X_test), axis=0)\n",
    "        self.y= np.concatenate((y_train, y_test), axis=0)\n",
    " \n",
    "\n",
    "    def euclidean(self, data, parameters=(1,False)):\n",
    "    \n",
    "        n_neighbors =parameters[0] \n",
    "        tuning=parameters[1] \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "       \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_neighbors': [1, 2, 3, 4, 5],'p':[2]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, pyts.classification.KNeighborsClassifier(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = pyts.classification.KNeighborsClassifier(n_neighbors ,p=2)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "            \n",
    "        \n",
    "        return cf\n",
    "        \n",
    "        \n",
    "\n",
    "    def tsf(self, data, parameters=(500,1, 1, False)):\n",
    "      \n",
    "        n_estimators=parameters[0]\n",
    "        n_windows=parameters[1]\n",
    "        min_window_size=parameters[2]\n",
    "        tuning=parameters[3] \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_estimators': [300,400,500,600,1000],'n_windows':[1], 'min_window_size': [1,3,5,10], 'random_state':[1]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, TimeSeriesForest(), param_grid)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            clf = TimeSeriesForest(n_estimators=parameters[0],n_windows=parameters[1],min_window_size=parameters[2],random_state=1)\n",
    "            clf.fit(X_train, y_train)\n",
    "        \n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "        \n",
    "        return cf\n",
    "\n",
    "\n",
    "    def dtw(self, data, parameters=(1,False)):\n",
    "      \n",
    "        \n",
    "        n_neighbors =parameters[0] \n",
    "        tuning=parameters[1] \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_neighbors': [1, 2, 3, 4, 5],'metric':['dtw']}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, pyts.classification.KNeighborsClassifier(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = pyts.classification.KNeighborsClassifier(n_neighbors ,metric='dtw')\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "        \n",
    "        return cf\n",
    "    \n",
    "    \n",
    "    \n",
    "    def ciddtw(self,data,parameters=(1,False)):\n",
    "   \n",
    "        def mydist(Q, C):\n",
    "            \n",
    "            CE_Q = np.sqrt(np.sum(np.diff(Q)**2))\n",
    "            CE_C= np.sqrt(np.sum(np.diff(C)**2))\n",
    "            return  pyts.metrics.dtw(Q,C)*(np.maximum(CE_Q,CE_C)/np.minimum(CE_Q,CE_C))\n",
    "    \n",
    "        n_neighbors =parameters[0] \n",
    "        tuning=parameters[1] \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_neighbors': [1, 2, 3, 4, 5],'metric':[mydist]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, pyts.classification.KNeighborsClassifier(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = pyts.classification.KNeighborsClassifier(n_neighbors ,metric=mydist)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "            \n",
    "        \n",
    "        return cf\n",
    "    \n",
    "    def msm(self, data , parameters=(1,False)):\n",
    "      \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        n_neighbors = parameters[0] \n",
    "        tuning = parameters[1] \n",
    "        \n",
    "        def mydist(x, y):\n",
    "            return distance(x, y, metric='msm')\n",
    "        \n",
    "             \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_neighbors': [1, 2, 3, 4, 5],'metric':[mydist]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, pyts.classification.KNeighborsClassifier(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = pyts.classification.KNeighborsClassifier(n_neighbors , metric=mydist)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "            \n",
    "        \n",
    "        return cf   \n",
    "    \n",
    "    \n",
    "    def svm_ndtw(self,data,parameters=(1,False)):\n",
    "      \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        C = parameters[0] \n",
    "        tuning = parameters[1]\n",
    "        \n",
    "        def NDTW_kernel(X1,X2):\n",
    "            return np.array([[-pyts.metrics.dtw(_x1,_x2) for _x2 in X2] for _x1 in X1])\n",
    "        \n",
    "        \n",
    "        clf = svm.SVC(kernel=NDTW_kernel, C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds=clf.predict(X_test)\n",
    "        cf=[y_test, preds]\n",
    "        \n",
    "        return cf\n",
    "        \n",
    "    \n",
    "    def svm_gdtw(self, data, parameters=(1,2,False)):\n",
    "         \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        sigma = parameters[0] \n",
    "        C = parameters[1] \n",
    "        tuning = parameters[2]\n",
    "        \n",
    "        def build_kernel_GDTW(sigma):\n",
    "            def GDTW_kernel(X1,X2):\n",
    "                return np.array([[np.exp(-pyts.metrics.dtw(_x1,_x2)**2/sigma**2) for _x2 in X2] for _x1 in X1])\n",
    "            return GDTW_kernel\n",
    "        \n",
    "        \n",
    "        clf = svm.SVC(kernel=build_kernel_GDTW(sigma), C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds=clf.predict(X_test)\n",
    "        cf=[y_test, preds]\n",
    "        return cf\n",
    "            \n",
    "    \n",
    "    def svm_gak(self,data,parameters=(2,1,False)):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        gamma = parameters[0] \n",
    "        C = parameters[1] \n",
    "        tuning = parameters[2]\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [2, 1, 0.1, 0.01]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, TimeSeriesSVC(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = TimeSeriesSVC(C=C,kernel='gak', gamma=gamma)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "            \n",
    "        \n",
    "        return cf   \n",
    "\n",
    "        \n",
    "    def svm_rbf(self,data, parameters=(1,2,False)):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        gamma = parameters[0] \n",
    "        C = parameters[1] \n",
    "        tuning = parameters[2]\n",
    "        \n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [2, 1, 0.1, 0.01, 0.001],'kernel':['rbf']}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, TimeSeriesSVC(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = TimeSeriesSVC(C=C, kernel='rbf', gamma=gamma)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "             \n",
    "        return cf   \n",
    "    \n",
    "    def bossvs(self, data, parameters=(4, 4, 10, False)):\n",
    "\n",
    "        word_size =parameters[0] \n",
    "        n_bins = parameters[1] \n",
    "        window_size= parameters[2] \n",
    "        tuning=parameters[3] \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'word_size': [3,4,5,6],'n_bins':[4],'window_size':[10,15,20]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, BOSSVS(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = BOSSVS(word_size, n_bins, window_size)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "            \n",
    "        \n",
    "        return cf\n",
    "    \n",
    "    def saxvsm(self, data, parameters=(0.5,0.5,4,False)):\n",
    "        \n",
    "        window_size =parameters[0] \n",
    "        word_size = parameters[1] \n",
    "        n_bins= parameters[2] \n",
    "        tuning=parameters[3] \n",
    "\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'window_size': [0.3,0.4,0.5,0.6],'word_size':[0.2,0.3,0.4,0.5],'n_bins':[4],'strategy':['normal']}\n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, SAXVSM(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = SAXVSM(window_size, word_size, n_bins, strategy='normal')\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "            \n",
    "        return cf\n",
    "        \n",
    "        \n",
    "    def characteristic_based(self, data, parameters=(1,False)):\n",
    "        \n",
    "        n_neighbors =parameters[0] \n",
    "        tuning=parameters[1] \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_neighbors': [1, 2, 3, 4, 5],'p':[2]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, sklearn.neighbors.KNeighborsClassifier(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors ,p=2)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "        \n",
    "        return cf\n",
    "        \n",
    "        \n",
    "    def acf(self,data,parameters=(1,False)):\n",
    "     \n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        \n",
    "        n_neighbors = parameters[0] \n",
    "        tuning = parameters[1] \n",
    "        \n",
    "        def mydist(x, y):\n",
    "            \n",
    "            x1=pd.Series(x)\n",
    "            x2=pd.Series(y)\n",
    "\n",
    "            dfx=pd.to_numeric(x1)\n",
    "            dfy=pd.to_numeric(x2)\n",
    "\n",
    "            return Tdist.ACFDistance(dfx,dfy)[0]\n",
    "        \n",
    "             \n",
    "        if tuning==True:     \n",
    "            param_grid = {'n_neighbors': [1, 2, 3, 4, 5],'metric':[mydist]}  \n",
    "            cf= self.parameter_tuning(X_train, X_test, y_train, y_test, pyts.classification.KNeighborsClassifier(), param_grid)\n",
    "         \n",
    "        else:\n",
    "        \n",
    "            clf = pyts.classification.KNeighborsClassifier(n_neighbors , metric=mydist)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds=clf.predict(X_test)\n",
    "            cf=[y_test, preds]\n",
    "              \n",
    "        return cf\n",
    "        \n",
    "\n",
    "    \n",
    "    def classification(self, method, params=None):\n",
    "        \n",
    "        self.results=[]\n",
    "        st = time.process_time()\n",
    "        st1 = time.time()\n",
    "    \n",
    "\n",
    "        for i in range(0,self.splits_number):\n",
    "            data=self.datasets[i]\n",
    "            m = getattr(self, method)\n",
    "            if params==None:\n",
    "                self.results.append(m(data)) \n",
    "            else:\n",
    "                self.results.append(m(data,params)) \n",
    "         \n",
    "            et = time.process_time()\n",
    "            res = et - st\n",
    "            et1 = time.time()\n",
    "            res1 = et1 - st1\n",
    "        \n",
    "        self.time_results= ['Execution time', res1 ,'CPU Execution time', res]\n",
    "        \n",
    "        self.save_results(method)\n",
    "    \n",
    "    \n",
    "        return self.results\n",
    "    \n",
    "\n",
    "    def split_data(self,test_size):\n",
    "        \n",
    "        self.datasets  = {key: train_test_split(self.X, self.y, test_size=test_size, random_state=key, \n",
    "                                                stratify=self.y) for key in range(1,self.splits_number)}\n",
    "        \n",
    "        self.datasets[0]= (self.X_train,self.X_test,self.y_train,self.y_test)\n",
    "        return self.datasets\n",
    "        \n",
    " \n",
    "\n",
    "    def parameter_tuning(self, X_train, X_test, y_train, y_test, method, parameters_grid):\n",
    "        \n",
    "        \n",
    "        grid = GridSearchCV(method, parameters_grid, refit = True) \n",
    "        grid.fit(X_train, y_train) \n",
    "        grid_predictions = grid.predict(X_test) \n",
    "        cf=[y_test, grid_predictions]\n",
    "        \n",
    "        return cf\n",
    "    \n",
    "    \n",
    "    def data_transform(self, transformation, window=3):\n",
    "        \n",
    "        nd=self.X_train.copy()\n",
    "        nd2=self.X_test.copy()\n",
    "        nd3=self.X.copy()\n",
    "        box_lambda=self.X_train.copy()\n",
    "        \n",
    "        if transformation=='standardization':\n",
    "            \n",
    "            scaler=sklearn.preprocessing.StandardScaler()\n",
    "            \n",
    "            scaler.fit(nd.T)\n",
    "            X_train=scaler.transform(nd.T)\n",
    "            self.X_train=X_train.T\n",
    "            \n",
    "            scaler.fit(nd2.T)\n",
    "            X_test=scaler.transform(nd2.T)\n",
    "            self.X_test=X_test.T\n",
    "            \n",
    "            scaler.fit(nd3.T)\n",
    "            X=scaler.transform(nd3.T)\n",
    "            self.X=X.T\n",
    "            \n",
    "        if transformation=='smoothing':\n",
    "            \n",
    "            l=np.shape(nd)[1]\n",
    "            \n",
    "            nd_pd = pd.DataFrame(nd.T)\n",
    "            nd2_pd = pd.DataFrame(nd2.T)\n",
    "            nd3_pd = pd.DataFrame(nd3.T)\n",
    "            \n",
    "            rolling = nd_pd.rolling(window,center=True)\n",
    "            rolling2 = nd2_pd.rolling(window,center=True)\n",
    "            rolling3 = nd3_pd.rolling(window,center=True)\n",
    "            rolling_mean = rolling.mean()\n",
    "            rolling_mean2 = rolling2.mean()\n",
    "            rolling_mean3 = rolling3.mean()\n",
    "            x=rolling_mean[int((window-1)/2):int(l-((window-1)/2))]\n",
    "            x2=rolling_mean2[int((window-1)/2):int(l-((window-1)/2))]\n",
    "            x3=rolling_mean3[int((window-1)/2):int(l-((window-1)/2))]\n",
    "            \n",
    "            x=x.T\n",
    "            x2=x2.T\n",
    "            x3=x3.T\n",
    "            \n",
    "            self.X_train=x.to_numpy()\n",
    "            self.X_test=x2.to_numpy()\n",
    "            self.X=x3.to_numpy()\n",
    "            \n",
    "        if transformation=='box_cox':\n",
    "            \n",
    "            negative=False\n",
    "            min_list=[]\n",
    "            for i in nd3:\n",
    "                min_list.append(min(i))\n",
    "                \n",
    "            if min(min_list)<0:\n",
    "                negative = True\n",
    "                    \n",
    "                    \n",
    "            if negative == True:\n",
    "            \n",
    "                for i in range(0,np.shape(nd)[0]):\n",
    "                    print('real szereg:',nd[i])\n",
    "                    nd[i]=stats.boxcox(nd[i]-min(min_list)+1)[0]\n",
    "                    box_lambda[i]=stats.boxcox(nd[i]-min(min_list)+1)[1]\n",
    "                    print('box szereg:',nd[i])\n",
    "                for i in range(0,np.shape(nd2)[0]):\n",
    "                    nd2[i]=stats.boxcox(nd2[i]-min(min_list)+1)[0]\n",
    "                \n",
    "                for i in range(0,np.shape(nd3)[0]):\n",
    "                    nd3[i]=stats.boxcox(nd3[i]-min(min_list)+1)[0]\n",
    "            else:\n",
    "                \n",
    "                for i in range(0,np.shape(nd)[0]):\n",
    "                    print('real szereg:',nd[i])\n",
    "                    nd[i]=stats.boxcox(nd[i])[0]\n",
    "                    box_lambda[i]=stats.boxcox(nd[i])[0]\n",
    "                    print('box szereg:',nd[i])\n",
    "                    \n",
    "                for i in range(0,np.shape(nd2)[0]):\n",
    "                    nd2[i]=stats.boxcox(nd2[i])[0]\n",
    "                \n",
    "                for i in range(0,np.shape(nd3)[0]):\n",
    "                    nd3[i]=stats.boxcox(nd3[i])[0]\n",
    "                \n",
    "            self.X_train=nd\n",
    "            self.X_test=nd2\n",
    "            self.X=nd3\n",
    "            \n",
    "        return box_lambda \n",
    "\n",
    "    def save_results(self, method):\n",
    "\n",
    "        results_data = self.results\n",
    "        time_data = self.time_results\n",
    "         \n",
    "        with open(self.path+method+'.pickle', 'wb') as handle:\n",
    "            pickle.dump(results_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            pickle.dump(time_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(path):\n",
    "    \n",
    "    with open(path, 'rb') as handle:\n",
    "        result_data = pickle.load(handle)\n",
    "        time_data = pickle.load(handle)\n",
    "             \n",
    "    accuracy_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_list=[]\n",
    "    cm_list=[]\n",
    "    \n",
    "    for i in result_data:\n",
    "        if max(i[0])>1:\n",
    "            a=accuracy_score(i[0], i[1])\n",
    "            p=precision_score(i[0], i[1],average='macro')\n",
    "            r=recall_score(i[0], i[1],average='macro')\n",
    "            f=f1_score(i[0], i[1],average='macro')\n",
    "            \n",
    "        else:   \n",
    "            a=accuracy_score(i[0], i[1])\n",
    "            p=precision_score(i[0], i[1])\n",
    "            r=recall_score(i[0], i[1])\n",
    "            f=f1_score(i[0], i[1])\n",
    "        \n",
    "        accuracy_list.append(a)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        f1_list.append(f)\n",
    "        \n",
    "    mean_accuracy=np.mean(accuracy_list)\n",
    "    deviation_accuracy=np.std(accuracy_list)\n",
    "    mean_p=np.mean(precision_list)\n",
    "    deviation_p=np.std(precision_list)\n",
    "    mean_r=np.mean(recall_list)\n",
    "    deviation_r=np.std(recall_list)\n",
    "    mean_f=np.mean(f1_list)\n",
    "    deviation_f=np.std(f1_list)\n",
    "   \n",
    "    \n",
    "    return (mean_accuracy,deviation_accuracy,mean_p,deviation_p,mean_r,deviation_r,mean_f,deviation_f,time_data[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
